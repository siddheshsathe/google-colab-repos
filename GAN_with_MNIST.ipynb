{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN with MNIST",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOj3Uq3h9JDMfj/tr654fxv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddheshsathe/google-colab-repos/blob/master/GAN_with_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a4u4Hj1x-XH",
        "colab_type": "text"
      },
      "source": [
        "# Using MNIST data for learning working of GANs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LiumFTQyH4H",
        "colab_type": "text"
      },
      "source": [
        "Below are the steps that we'll be following\n",
        "<br>\n",
        "* Load data using `keras`'s built in `load_data`\n",
        "* For demo/learning purpose we'll just use any one data class (anyone from 0 through 9), let's use 1\n",
        "* Create `generator` model \n",
        "> * This model will have any latent (primary input noise) shape \n",
        "> * Eventually we'll make this with reshaping and/or upsampling the 2D images to the desired output image shape\n",
        "> * While building this model, we'll not compile this as it will be compiled directly in the complete GAN model\n",
        "* Create `discriminator` model\n",
        "> * This model will just be a `binary classification` model which will output that the input to this model is a real or a fake image\n",
        "> * Thus the output layer will consist of a `Dense` layer with single neuron.\n",
        "> * Input shape of this model is of input image shape\n",
        "> * Compile the model with `binary_crossentropy` and any suitable optimizer\n",
        "* The training phase of this GAN model is not just usual with `fit` method\n",
        "* We'll need to train the `discriminator` with below labels\n",
        "> * `fake = 0`\n",
        "> * `real = 1`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBPiecdS6dVX",
        "colab_type": "text"
      },
      "source": [
        "#1. Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTUa7we5xgTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "import numpy as np\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1a0AaBp7SGc",
        "colab_type": "text"
      },
      "source": [
        "#2. Defining the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIHBeFr06rYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, UpSampling2D, Flatten, LeakyReLU, BatchNormalization, Reshape, Conv2DTranspose, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34DMAOL2HzW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coding_size = 100 # Initial latent size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3CtYHfg7zlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = Sequential()\n",
        "\n",
        "generator.add(Dense(7 * 7 * 128, input_shape=[coding_size]))\n",
        "generator.add(Reshape([7, 7, 128]))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\",\n",
        "                                 activation=\"relu\"))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"same\",\n",
        "                                 activation=\"tanh\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPHhy5oL_Npo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = Sequential()\n",
        "discriminator.add(Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
        "                        activation=LeakyReLU(0.3),\n",
        "                        input_shape=[28, 28, 1]))\n",
        "discriminator.add(Dropout(0.5))\n",
        "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\",\n",
        "                        activation=LeakyReLU(0.3)))\n",
        "discriminator.add(Dropout(0.5))\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(1, activation=\"sigmoid\"))\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WscWwfx_ivc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN = Sequential([generator, discriminator])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmLei45f_y_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKG-tYlY_6Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmzBsU1vACBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpZ7PWR2AlUR",
        "colab_type": "text"
      },
      "source": [
        "#3. Setting up training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd6QfyBgAGeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size=coding_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlvowxtKB1ND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkR_zd6YC5wh",
        "colab_type": "text"
      },
      "source": [
        "#4. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9DG8VajB8b9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "# Grab the seprate components\n",
        "generator, discriminator = GAN.layers\n",
        "\n",
        "# For every epcoh\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Currently on Epoch {epoch+1}\")\n",
        "    i = 0\n",
        "    # For every batch in the dataset\n",
        "    for X_batch in dataset:\n",
        "        i=i+1\n",
        "        if i%10 == 0:\n",
        "            print(f\"Batch: {i}\")\n",
        "        ## Training discriminator\n",
        "        \n",
        "        # Create Noise\n",
        "        noise = tf.random.normal(shape=[batch_size, coding_size])\n",
        "        \n",
        "        # Generate numbers based just on noise input\n",
        "        gen_images = generator(noise)\n",
        "        \n",
        "        # Concatenate Generated Images against the Real Ones\n",
        "        # TO use tf.concat, the data types must match!\n",
        "        X_fake_vs_real = tf.concat([gen_images, tf.dtypes.cast(X_batch,tf.float32)], axis=0)\n",
        "        \n",
        "        # Targets set to zero for fake images and 1 for real images\n",
        "        yLabel = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "        \n",
        "        # This gets rid of a Keras warning\n",
        "        discriminator.trainable = True\n",
        "        \n",
        "        # Train the discriminator on this batch\n",
        "        discriminator.train_on_batch(X_fake_vs_real, y1)\n",
        "        \n",
        "        \n",
        "        ## Training generator\n",
        "        # Using same noise\n",
        "        \n",
        "        # We want discriminator to belive that fake images are real\n",
        "        yLabel = tf.constant([[1.]] * batch_size)\n",
        "        \n",
        "        # Avois a warning\n",
        "        discriminator.trainable = False\n",
        "        \n",
        "        GAN.train_on_batch(noise, y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb8hmSzPNyyB",
        "colab_type": "text"
      },
      "source": [
        "# 5. Generating data with trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F77dAhOGGnH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = tf.random.normal([1, coding_size])\n",
        "noise.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCjAi4XUOBqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_image = generator(noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNOJF0i3OH5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcoDHF3zOTKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK-GtivQOXex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(generated_image[0].numpy().reshape(28, 28), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y-2sJqDOev2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}